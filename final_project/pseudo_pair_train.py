# -*- coding: utf-8 -*-
"""Generative adversarial network

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bq7RrTN6B9kunxh0jE8L-FNgMrk-ZI6C

# **Anime Character Generation using DC-GAN in PyTorch**
"""

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import os
import random
import torch
import torch.nn as nn
import torch.optim as optim
import torch.utils.data
import torchvision.datasets as datasets
import torchvision.transforms as transforms
import torchvision.utils as utils
import numpy as np
import matplotlib.pyplot as plt
from image_transform_net import ImageTransformNet
import pylab
import utils as FNS_utils

batch_size = 16
image_size = 256
ndf = 64 # Size of feature maps in discriminator
EPOCH = 50
lr = 0.0002 
record_epoch_period = 1

# We can use an image folder dataset the way we have it setup.
# Create the dataset
path = './data'
dataset = datasets.ImageFolder(path,
                        transform=transforms.Compose([
                            transforms.Resize(image_size),
                            transforms.CenterCrop(image_size),
                            transforms.ToTensor(),
                            transforms.Normalize(mean = [0.485, 0.456, 0.406],
                                                 std  = [0.229, 0.224, 0.225])
                           ]))
# Create the dataloader
dataloader = torch.utils.data.DataLoader(dataset, batch_size = batch_size, shuffle = True, num_workers = 2)

# Decide which device we want to run on
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
print('using device:',device)
print('size of training data:',len(dataset))
# Plot some training images
real_batch = next(iter(dataloader))
fig = plt.figure(figsize=(10,10))
plt.axis("off")
plt.imshow(np.transpose(utils.make_grid(real_batch[0].to(device)[:16], padding=2, normalize=True).cpu(),(1,2,0)))
"""Model"""

# weight initialization
# custom weights initialization called on netG and netD
def weights_init(m):
    classname = m.__class__.__name__
    if classname.find('Conv') != -1:
        nn.init.normal_(m.weight.data, 0.0, 0.02)
    elif classname.find('BatchNorm') != -1:
        nn.init.normal_(m.weight.data, 1.0, 0.02)
        nn.init.constant_(m.bias.data, 0)

# Generator
# Generator Code
class ConvLayer(nn.Module):
    def __init__(self,in_channels,out_channels,kernel_size,stride):
        super(ConvLayer,self).__init__()
        padding = kernel_size // 2
        self.reflect_pad = nn.ReflectionPad2d(padding)
        self.conv2d = nn.Conv2d(in_channels, out_channels, kernel_size, stride)
    
    def forward(self, x):
        x = self.reflect_pad(x)
        out = self.conv2d(x)
        return out

class UpsampleConvLayer(nn.Module):
    def __init__(self,in_channels,out_channels,kernel_size,stride,up_sample=None):
        super(UpsampleConvLayer, self).__init__()
        self.up_sample = up_sample
        padding = kernel_size // 2
        self.reflect_pad = nn.ReflectionPad2d(padding)
        self.conv2d = nn.Conv2d(in_channels,out_channels,kernel_size,stride)
    
    def forward(self, x):
        if self.up_sample:
            x = nn.functional.interpolate(x, mode='nearest',scale_factor=self.up_sample)
        x = self.reflect_pad(x)
        out = self.conv2d(x)
        return out

class ResidualBlock(nn.Module):
    def __init__(self, channels):
        super(ResidualBlock, self).__init__()
        self.conv1 = ConvLayer(channels,channels,kernel_size=3,stride=1)
        self.IN1 = nn.InstanceNorm2d(channels,affine=True)
        self.conv2 = ConvLayer(channels,channels,kernel_size=3,stride=1)
        self.IN2 = nn.InstanceNorm2d(channels,affine=True)
        self.relu = nn.ReLU()
    
    def forward(self,x):
        res = x
        x = self.relu(self.IN1(self.conv1(x)))
        x = self.relu(self.IN2(self.conv2(x)))
        out = x + res
        return out

class pseudo_pair_gan(nn.Module):
    def __init__(self):
        super(pseudo_pair_gan, self).__init__()
        self.relu = nn.ReLU()
        # Encoding Layer
        self.conv1 = ConvLayer(3,16,kernel_size=3,stride=1)
        self.IN1 = nn.InstanceNorm2d(16,affine=True)
        self.conv2 = ConvLayer(16,32,kernel_size=3,stride=2)
        self.IN2 = nn.InstanceNorm2d(32,affine=True)
        self.conv3 = ConvLayer(32,64,kernel_size=3,stride=2)
        self.IN3 = nn.InstanceNorm2d(64,affine=True)
        # Residual Layer
        self.res1 = ResidualBlock(64)
        # Decoding Layer
        self.deconv3 = UpsampleConvLayer(64,32,kernel_size=3, stride=1, up_sample=2)
        self.IN4 = nn.InstanceNorm2d(32, affine=True)
        self.deconv2 = UpsampleConvLayer(32,16,kernel_size=3, stride=1, up_sample=2)
        self.IN5 = nn.InstanceNorm2d(16,affine=True)
        self.deconv1 = UpsampleConvLayer(16,3,kernel_size=9, stride=1)
    
    def forward(self, x):
        x = self.relu(self.IN1(self.conv1(x)))
        x = self.relu(self.IN2(self.conv2(x)))
        x = self.relu(self.IN3(self.conv3(x)))
        x = self.res1(x)

        x = self.relu(self.IN4(self.deconv3(x)))
        x = self.relu(self.IN5(self.deconv2(x)))
        x = self.deconv1(x)
        return x

# discriminator
class Discriminator(nn.Module):
    def __init__(self):
        super(Discriminator, self).__init__()
        self.conv = nn.Sequential(
            nn.Conv2d(3, ndf, kernel_size = 5, stride = 2, padding = 2, bias=False),
            nn.BatchNorm2d(ndf),
            nn.ReLU(True),
            
            nn.Conv2d(ndf, ndf * 2, kernel_size = 5, stride = 2, padding = 2, bias=False),
            nn.BatchNorm2d(ndf * 2),
            nn.ReLU(True),

            nn.Conv2d(ndf * 2, ndf * 4, kernel_size = 3, stride = 2, padding = 1, bias=False),
            nn.BatchNorm2d(ndf * 4),
            nn.ReLU(True),

            nn.Conv2d(ndf * 4, ndf * 8, kernel_size = 3, stride = 2, padding = 1, bias=False),
            nn.BatchNorm2d(ndf * 8),
            nn.ReLU(True),
            
            
            nn.Conv2d(ndf * 8, ndf * 16, kernel_size = 3, stride = 2, padding = 1, bias=False),
            nn.BatchNorm2d(ndf * 16),
            nn.ReLU(True),

            nn.Conv2d(ndf * 16, ndf * 8, kernel_size = 3, stride = 2, padding = 1, bias=False),
            nn.BatchNorm2d(ndf * 8),
            nn.ReLU(True),

            nn.Conv2d(ndf * 8, ndf * 4, kernel_size = 3, stride = 2, padding = 1, bias=False),
            nn.BatchNorm2d(ndf * 4),
            nn.ReLU(True),

            nn.Conv2d(ndf * 4, 1, kernel_size = 3, stride = 2, padding = 1, bias=False),
            nn.Softmax()
        )
    def forward(self, input):
        x = self.conv(input)

        # print(x.shape)
        # x = self.linear(x)
        return x

student_netG = pseudo_pair_gan().to(device)

with torch.no_grad():
    teacher_netG = ImageTransformNet()
    teacher_netG.load_state_dict(torch.load('./models/matrix.model'))

teacher_netG.to(device)

netD = Discriminator().to(device)
netD.apply(weights_init)

"""# **Training**"""

# Training

# Lists to keep track of progress
criterion = nn.BCELoss()
recon_loss = nn.MSELoss(size_average=None, reduce=None, reduction='mean')

real_label = 1
fake_label = 0

optimizerD = optim.Adam(netD.parameters(), lr=lr)
optimizerG = optim.Adam(student_netG.parameters(), lr=lr)

img_list = []
G_losses = []
D_losses = []
ax_list = []
iters = 0

# For each epoch
for epoch in range(20):
    # For each batch in the dataloader
    for i, data in enumerate(dataloader, 0):

        
        netD.zero_grad()
        # Train real batch

        data = data[0].to(device)
        pseudo_real_batch = teacher_netG(data)
        label_size = pseudo_real_batch.size(0)
        
        # fig = plt.figure(figsize=(1,1))
        # plt.axis("off")
        # plt.imshow(np.transpose(utils.make_grid(pseudo_real_batch[0].to(device)[:16], padding=2, normalize=True).cpu(),(1,2,0)))
        # fig.savefig('transformed.png', dpi=200)        

        label = np.zeros((label_size,), dtype=np.int)
        label += real_label
        label = torch.tensor(label, dtype=torch.float, device = device)
        
        output = netD(pseudo_real_batch).view(-1)
        # print(pseudo_real_batch.shape)
        # print(output)
        D_loss_real = criterion(output, label)
        D_loss_real.backward(retain_graph = True)

        # Train fake batch
        fake = student_netG(data)

        label = np.zeros((label_size,), dtype=np.int)
        label = torch.tensor(label, dtype=torch.float, device = device)
        # print(fake.shape)
        # fig = plt.figure(figsize=(1,1))
        # plt.axis("off")

        # plt.imshow(np.transpose(utils.make_grid(fake[0].to(device), padding=2, normalize=True).cpu(),(1,2,0)))
        # fig.savefig('student_netG_transformed.png', dpi=200)

        output = netD(fake.detach()).view(-1)
        D_loss_fake = criterion(output, label)
        D_loss_fake.backward(retain_graph = True)
        
        D_loss = D_loss_real + D_loss_fake
        # print(D_loss_real.item(), D_loss_real.item())
        optimizerD.step()

        # Update G 
        student_netG.zero_grad()
        
        label = np.zeros((label_size,), dtype=np.int)
        label += real_label
        label = torch.tensor(label, dtype=torch.float, device = device)

        output = netD(fake).view(-1)

        G_loss = criterion(output, label)
        G_recon_loss = recon_loss(pseudo_real_batch, fake)
        G_loss.backward(retain_graph=True)
        G_recon_loss.backward( )

        G_loss_total = G_loss + G_recon_loss
        optimizerG.step()

        # Output training stats
        if i % 50 == 0:
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f'% (epoch, EPOCH, i, len(dataloader),D_loss.item(), G_loss_total.item()))

        # Save Losses for plotting later
        G_losses.append(G_loss.item())
        D_losses.append(D_loss.item())
        ax_list.append(iters)

        # Check how the generator is doing by saving G's output on fixed_noise
        if epoch % record_epoch_period == 0 and (i == len(dataloader) - 1):
            with torch.no_grad():
                fake = student_netG(data).detach().cpu()
            img_list.append(utils.make_grid(fake, padding=2, normalize=True))
            torch.save(student_netG.state_dict(), './models/student_model_G_' + str(epoch) + '-epoch.model')
            print('model_saved')


        iters += 1

